# Prompt Engineering Cookbook

This cookbook will discuss prompt engineering skills and outline how to optimize your prompts to achieve the expected results from a model. It will include optimized prompt examples for standardized generative models.

**What is Prompt Engineering?**

Prompt engineering refers to the iterative process of modifying natural-language instructions, known as _prompts,_ and using various prompt techniques to guide generative AI models toward improved outputs.

The techniques discussed in this cookbook can be applied when writing prompts for any generative multimodal model, regardless of training. It also encompasses both **System Messages** to establish the model's behavior and constraints before user interaction begins, as well as **Assistant messages** that influence the model's responses in multi-turn conversations. They both maintain conversation continuity and help the model understand its established persona and previous commitments.

## **Prompt Anatomy**

A good prompt requires several key elements to be present:

- **Role**: This refers to the persona assigned to a model to guide its behavior and responses.
- **Task**: The task provides a detailed description of the model's objective and outlines the approach to executing it.
- **Input Context**: Input context is the information, background, and situational details passed to the model. This input can be structured or unstructured text, as well as multimodal content such as files, images, or audio. Accurate context is essential for grounding the model's outputs with user intent.
- **Output**: This is the format in which a model generates its response. You determine how the model communicates results, ranging from plain text to code snippets, JSON objects, or formatted prose.
- **Constraints**: Prompt constraints are the guidelines that define how the model should behave when responding to user prompts.
- **Tools**: Tools are external functions or APIs that a model can invoke to enhance its responses or perform tasks beyond its native language generation capabilities.

Depending on the prompt's objective, certain elements may be excluded. Prompt engineering should be approached in the same way as writing code. Understanding the objective of your prompt should influence how you structure an effective prompt message.

### Structuring Prompt Hierarchy

Most models exhibit symptoms of **_recency bias_**, where the most recent instruction in the prompt takes precedence over all other elements.

Language models are sensitive to token order: if task instructions are buried in a prompt, the model will keep expanding the background context and miss the goal. Clear directives will help maintain focus, avoid misinterpretation, and reduce drift.

Adopt a top-to-bottom prompt hierarchy, placing essential instructions at the bottom of the prompt.

A solid starting point for structuring your prompt hierarchy comes from OpenAIâ€™s GPT-4.1 prompt guide. This structure works reliably across any generative model.

```bash
# Role and Objective
# Instructions
## Sub-categories for more detailed instructions
# Reasoning Steps
# Output Format
# Examples
## Example 1
# Context
# Final instructions and prompt to think step by step
```

### Delimiters

**Delimiters** are markers that organize different parts of a prompt or model response.

LLMs are trained on extensive, structured data in various formats. During training and fine-tuning, a model is taught to process text through tokenization and recognize format patterns (_delimiters_).

Since [transformers](<https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)>) utilize attention mechanisms to understand the relationships between tokens, models look for these delimiters that highlight parts of a prompt not to overlook.
Without delimiters, the model must infer boundaries and formats from context alone, which is prone to error and can get computationally expensive.

`Markdown`, `JSON` and `XML` tags are excellent delimiters for inferring structure to your prompts.

```
<!-- XML-style Delimiters -->
<prompt>
  <role>Research Assistant</role>
  <objective>Summarize a technical article</objective>

  <!-- Markdown-style Instructions -->
  # Instructions
  - Read the text carefully
  - Extract key points
  - Write a concise summary in plain English

  ## Reasoning Steps
  1. Identify core arguments
  2. Group related points
  3. Translate to summary format

  # Output Format (JSON-style)
  {
    "summary": "[Plain text summary]",
    "keyPoints": ["Point 1", "Point 2", "Point 3"]
  }

  # Example
  Input: "The article discusses tokenization in NLP..."
  Output: "This article explains how text is broken into tokens for processing."

  # Context
  Article provided by user

  # Final Prompt
  Think step by step and provide your summary in the specified format.
</prompt>
```

Only apply one of the delimiter option methods in your prompts. You should also maintain that choice across your conversation. You want to maintain a recognizable pattern within your conversational flow. As you can see in the example above, you can also include special characters to improve parsing accuracy.

## Multi-turn Conversations

Multi-turn conversations represent the extended interactions between users and the model across the chat.

There are two key considerations to keep in mind when engaging in an extended interaction with a chat model.

- **Context Window Maintenance**
- **Error Recovery**

### Context Maintenance

LLMs operate with a fixed context window. This constraint creates challenges for long conversations. Each new context turn in your prompts is appended to the existing conversation thread. The model must decide what information to retain and what to discard as the conversation approaches the window limit.

The entire thread is processed holistically by the model, allowing it to reference previous statements, questions, and responses in the conversation. You can imagine that it gets messy at some point; your model loses track of the plot and starts hallucinating information.

You can find a list of top language models and their context window capacities on Velum's LLM Ratings page.

![Context window, cost and speed comparison](../assets/context-window-comparison.png)

Here are some basic context reinforcement techniques to aid a model maintain context within your conversation.

**Establish Strong Context Foundations & Reference Anchors:** Begin conversations with comprehensive context that establishes the scope and purpose of your interaction. This establishes clear reference points for the model, avoiding discarding important context for your follow-up prompts. Having reference anchors will also force the model to maintain an understanding of your conversation, allowing you to reference those anchors at any time.

Using this technique, the model retains a global context of your conversation and passes that context to every response it outputs.

```

::: Context Foundation :::
  You are assisting with [project or scenario name]. The project involves [key background details and scope]. The deadline is [timeframe].
  Constraints include [any known limitations or requirements].

  Note: All responses should remain grounded in this context.. I may refer back to this block using the anchor [PROJECT_OVERVIEW].

  Now, when  you reference PROJECT_OVERVIEW deep into your thread, the model will have clear context."

  === Example ===
  Input: "Based on [PROJECT_OVERVIEW], what should I prioritize first?"
  Output: "Given your deadline, the first priority should be..."
```

**Use Structured Context Blocks:** Using delimiters to structure complex context will improve parsing accuracy. The clearer picture the model has of your conversation's scope and focus, the easier it'll be for it to maintain context and reference your anchors to make relationships.

**Periodic Context Summaries:** Provide summaries when conversations become complex or shift direction.

For example, the prompt below summarizes the discussion and indicates the direction the chat is heading next.

```
Input: "To summarize our discussion so far: we've established [PROJECT_OVERVIEW] and now we're working on [current conversation objective]. Next, I'd like to [new task] ."
```

**Selective Context Retention:** Not all data from your thread remains important to your conversation. Reference or repeat only the critical pieces of context to steer the model and avoid unintended associations. This practice is particularly effective when switching topics, refining previous outputs, or focusing the model's attention on a specific objective.
An example of how to perform this is below.

```
Input: "From our earlier conversation, the key technical decisions were: [PROJECT_OVERVIEW]. Skipping [Project_Detail] for now - let's focus on implementing [new task]."
```

### Error Recovery

**Use Confirmation Requests:** Ask for confirmation of understanding before proceeding.

```
Input: "Before we move ahead, let me confirm: you understand every objective along with all the information discussed in [PROJECT_OVERVIEW]?. Be sure to ask for clarification if anything is unclear."

Output: Model confirms or denies(asks for clarification)
```

When you spot an error, you can also employ context reconstruction to better align your prompts' objectives with the model's understanding.

### Example of an Ideal Conversation Flow

```
Opening: Establish clear context and objectives
Development: Build on previous context with explicit references
Maintenance: Periodically summarize and confirm understanding
Recovery: Address misunderstandings immediately
Closure: Summarize outcomes and next steps
```

<aside>
  Most models struggle to retain uploaded files in memory. For better results,
  copy relevant text into the chat. When building agents system prompt, you can
  upload this PDF [The Prompt Report: A Systematic Survey of Prompting
  Techniques](https://learning.coach/wp-content/uploads/2024/06/2024-The-Prompt-Report-A-Systematic-Survey-of-Prompting-Techniques.pdf)
  to provide the model with better context.
</aside>
